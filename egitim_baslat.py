import os
import gymnasium as gym
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.monitor import Monitor
import sumo_rl

# --- AYARLAR ---
HARITA_DOSYASI = "SUMO\map\grid_sehir.net.xml"
TRAFIK_DOSYASI = "SUMO\map\\traffic.rou.xml"
MODEL_ADI = "trafik_yonetici_ppo"
SIMULASYON_SURESI = 5000 # AdÄ±m sayÄ±sÄ± (Saniye)

def main():
    print("ðŸ¤– Trafik Yapay ZekasÄ± EÄŸitimi BaÅŸlÄ±yor...")
    print(f"Harita: {HARITA_DOSYASI}")
    print("Not: Pencere AÃ‡ILMAYACAK (HÄ±z iÃ§in). SabÄ±rlÄ± olun...")

    # 1. ORTAMI OLUÅžTUR
    # single_agent=True: PPO'nun hata vermemesi iÃ§in tek bir ajanÄ± yÃ¶netir.
    env = sumo_rl.SumoEnvironment(
        net_file=HARITA_DOSYASI,
        route_file=TRAFIK_DOSYASI,
        use_gui=False,             # EÄŸitimde grafik arayÃ¼zÃ¼ kapatÄ±yoruz
        num_seconds=SIMULASYON_SURESI,
        min_green=5,
        delta_time=5,
        reward_fn='diff-waiting-time',
        single_agent=True          # <--- KRÄ°TÄ°K AYAR (Hata almamak iÃ§in)
    )

    # OrtamÄ± loglama iÃ§in Monitor ile, uyumluluk iÃ§in DummyVecEnv ile sarÄ±yoruz
    env = Monitor(env)
    env = DummyVecEnv([lambda: env])

    # 2. MODELÄ° OLUÅžTUR (PPO)
    model = PPO(
        "MlpPolicy", 
        env, 
        verbose=1, 
        learning_rate=0.0003,
        batch_size=256
    )

    # 3. EÄžÄ°TÄ°MÄ° BAÅžLAT
    # 50.000 adÄ±m yaklaÅŸÄ±k 10-15 dakika sÃ¼rebilir (bilgisayar hÄ±zÄ±na gÃ¶re)
    EGITIM_ADIM = 50000 
    print(f"Hedeflenen AdÄ±m SayÄ±sÄ±: {EGITIM_ADIM}. BaÅŸlÄ±yor...")
    
    model.learn(total_timesteps=EGITIM_ADIM)

    # 4. KAYDET
    model.save(MODEL_ADI)
    print(f"\nâœ… EÄŸitim tamamlandÄ±! Model '{MODEL_ADI}.zip' olarak kaydedildi.")
    
    env.close()

if __name__ == "__main__":
    main()