import os
import sys
import gymnasium as gym
import numpy as np

# Windows HÄ±zlandÄ±rmasÄ±
if os.name != 'nt':
    os.environ['LIBSUMO_AS_TRACI'] = '1'

from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import SubprocVecEnv
from stable_baselines3.common.monitor import Monitor
import sumo_rl

# --- AYARLAR ---
HARITA_DOSYASI = "SUMO\map\grid_sehir.net.xml"
TRAFIK_DOSYASI = "SUMO\map\\traffic.rou.xml"
MODEL_ADI = "trafik_yonetici_4_kavsak_ceza01"
KARAR_SURESI = 15  
MIN_YESIL = 10
SIMULASYON_SURESI = 4000
ISLEM_SAYISI = 15   # Ã‡ekirdek SayÄ±sÄ±

# --- Ã–ZEL ADAPTER SINIFI (Wrapper DeÄŸil!) ---
# gym.Wrapper yerine direkt gym.Env kullanÄ±yoruz.
# BÃ¶ylece "AssertionError" hatasÄ±nÄ± baypas ediyoruz.
class PettingZooToGymAdapter(gym.Env):
    def __init__(self, pz_env):
        self.pz_env = pz_env
        self.possible_agents = pz_env.possible_agents
        
        # Ä°lk ajanÄ±n Ã¶zelliklerini alÄ±p Gym standardÄ± yapÄ±yoruz
        self.observation_space = pz_env.observation_space(self.possible_agents[0])
        self.action_space = pz_env.action_space(self.possible_agents[0])
        
        # Render mode
        self.render_mode = "rgb_array"
        self.metadata = {"render_modes": ["rgb_array"]}

        # --- EKLEMEN GEREKEN YER (1) ---
        # SÄ±nÄ±f ilk yaratÄ±ldÄ±ÄŸÄ±nda "Daha Ã¶nce hiÃ§bir ÅŸey yapmadÄ±m" diyoruz.
        self.last_action = None 
        # -------------------------------

    def reset(self, seed=None, options=None):
        # --- EKLEMEN GEREKEN YER (2) ---
        # Oyun sÄ±fÄ±rlandÄ±ÄŸÄ±nda hafÄ±zayÄ± da sÄ±fÄ±rlayalÄ±m
        self.last_action = None
        # -------------------------------

        obs_dict, info_dict = self.pz_env.reset(seed=seed, options=options)
        agent_id = self.possible_agents[0]
        return obs_dict[agent_id], info_dict[agent_id]

    def step(self, action):
        # AksiyonlarÄ± daÄŸÄ±t
        actions = {agent: action for agent in self.possible_agents}
        obs_dict, rewards, terminations, truncations, infos = self.pz_env.step(actions)
        
        # --- YENÄ° Ã–DÃœL MANTIÄžI ---
        # 1. Ham BaskÄ± PuanÄ±nÄ± Al (Negatif bir sayÄ±dÄ±r)
        raw_pressure = sum(rewards.values())
        
        # 2. DeÄŸiÅŸim CezasÄ± (Switch Penalty)
        switch_penalty = 0
        if self.last_action is not None and action != self.last_action:
            switch_penalty = 10  # CezayÄ± 10 yaptÄ±k
        
        # 3. Nihai Ã–dÃ¼l:
        # BaskÄ±yÄ± biraz kÃ¼Ã§Ã¼ltÃ¼yoruz (0.05 ile Ã§arpÄ±p) ki deÄŸiÅŸim cezasÄ±nÄ± yutmasÄ±n.
        # BÃ¶ylece model hem trafiÄŸi hem de deÄŸiÅŸimi dengeli gÃ¶rÃ¼r.
        total_reward = (raw_pressure * 0.05) - switch_penalty
        
        self.last_action = action
        # -------------------------

        obs = obs_dict[self.possible_agents[0]]
        done = any(terminations.values()) or any(truncations.values())
        info = infos[self.possible_agents[0]]
        
        return obs, total_reward, done, False, info

def make_env(rank):
    def _init():
        # 1. SUMO Parallel Env oluÅŸtur
        env = sumo_rl.parallel_env(
            net_file=HARITA_DOSYASI,
            route_file=TRAFIK_DOSYASI,
            use_gui=False,
            num_seconds=SIMULASYON_SURESI,
            min_green=MIN_YESIL,
            delta_time=KARAR_SURESI,
            reward_fn='pressure', 
        )
        
        # 2. Bizim yazdÄ±ÄŸÄ±mÄ±z Ã¶zel Adapter ile sar
        # Bu sÄ±nÄ±f Gym ortamÄ± gibi davranÄ±r ama arkada SUMO'yu yÃ¶netir
        env = PettingZooToGymAdapter(env)
        
        # 3. Monitor ekle
        env = Monitor(env)
        return env
    return _init

def main():
    print(f"ðŸš€ GARANTÄ° MULTI-AGENT EÄžÄ°TÄ°M BAÅžLIYOR ({ISLEM_SAYISI} Ã‡EKÄ°RDEK)...")
    
    # Ã‡oklu Ä°ÅŸlemci OrtamÄ±
    env = SubprocVecEnv([make_env(i) for i in range(ISLEM_SAYISI)])

    # Model
    model = PPO(
        "MlpPolicy", 
        env, 
        verbose=1,
        learning_rate=0.0003,
        batch_size=512,
        n_steps=1024
    )

    # EÄŸitim
    EGITIM_ADIM = 200000 
    print(f"Hedef: {EGITIM_ADIM} adÄ±m. Bekleyin...")
    
    model.learn(total_timesteps=EGITIM_ADIM)

    model.save(MODEL_ADI)
    print(f"\nâœ… EÄŸitim TamamlandÄ±! '{MODEL_ADI}.zip'")
    env.close()

if __name__ == "__main__":
    main()